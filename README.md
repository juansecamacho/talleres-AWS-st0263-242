# Laboratorios 0,1,2 y 3 
## Clase: Topicos Especiales en Telematica 
Nombre: Juan Sebastian Camacho
Correo jscamachop@eafit.edu.co

Profesor: Edwin Nelson Montoya
Correo: emontoya@eafit.edu.co

## Descripcion general 
Este repositorio tiene los laboratorios desarrollados en el curso, el cual se enfoca en el uso de tecnologias de Big Data, como Hadoop y Spark. Estas herramientas son muy utlies para gestionar y procesar grandes volumenes de informacion de una forma eficiente.

Los laboratorios tratan de lo siguiente:

## Laboratorio 0: Configuracion inical  ##

En este laboratorio se establece un entorno de trabajo en Amazon EMR, donde se configura un cluster de Hadoop en la nube. Este laboratorio funciona como una base para los siguientes laboratorios, ya que permite familiarizarse con las herramientas del procesamiento de Big Data

## Laboratorio 1: Administracion de archivos en HDFS y S3

Este laboratorio trata sobre la manipulacion y organizacion de archivos dentro de Hadoop y Amazon S3 o Buckets. Se trabajo la carga, gesion y estructuracion de archivos en un sistema de archivos distribuidos y en un entorno de almacenamiento en la nube. Se usaron comandos HDFS para las diferentes tareas y tambien se trabajo la transferencia de datos entre HDFS y S#.

## Laboratorio 2: Consultas y procesamiento de datos con HIVE y Spark

En este laboratorio se realizaron consulas y analisis de datos utilizando Hive y Spark, esto sobre datos que ya estaban almacenados en HDFS y S3. Se enfoca mucho en la gestion de grandes conjuntos de datos en un entorno de Big Data, se crearon tablas en Hive para poder realizar consultas.

## Laboratorio 3: Analisis de datos a gran escala con PySpark

Este reto implica realizar analisis sobre un conjunto de datos de casos de COVID-19, se aplicaron tecnicas de analisis de datos en un entorno distribuido, donde existia la opcion de almacenar los resultados en S3 y Google Drive.
